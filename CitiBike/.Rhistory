travel <- subset(data, name == "Travel")
summary(celebrity$variance)
sd(celebrity)
sd(celebrity$variance)
mean(celebrity$variance)
mean(celebrity$price)
sd(celebrity$price)
mean(celebrity$estimated)
mean(travel$estimated)
mean(travel$price)
sd(travel$estimated)
sd(travel$price)
summary(travel)
data <- read.csv("~/Documents/Data/fy14 variance.csv")
View(data)
sports <- subset(data,name == "Sports")
View(sports)
travel <- subset(data,name == "Travel")
celebrity <- subset(data,name == "Celebrity")
entertainment <- subset(data,name == "Entertainment")
bizexp <- subset(data,name == "Business Experiences")
summary(sports)
data <- read.csv("~/Documents/Data/fy14 variance.csv")
View(data)
sports <- subset(data,name == "Sports")
celebrity <- subset(data,name == "Celebrity")
entertainment <- subset(data,name == "Entertainment")
travel <- subset(data,name == "Travel")
bizexp <- subset(data,name == "Business Experiences")
summary(sports)
sd(sports$fvar)
sd(sports$svar)
summary(travel)
sd(travel$fvar)
sd(travel$svar)
summary(bizexp)
data <- read.csv("~/Documents/Data/fy14 variance.csv")
View(data)
sports <- subset(data,name == "Sports")
celebrity <- subset(data,name == "Celebrity")
entertainment <- subset(data,name == "Entertainment")
travel <- subset(data,name == "Travel")
bizexp <- subset(data,name == "Business Experiences")
summary(sports)
sd(sports$fpercent)
summary(travel)
summary(celebrity)
summary(bizexp)
sd(bizexp$fpercent)
summary(entertainment)
sd(entertainment$fpercent)
mean(entertainment$fpercent)
mean(entertainment$forecast)
sd(entertainment$forecast)
data <- read.csv("~/Documents/Data/fy14 variance.csv")
View(data)
summary(data)
class(data)
sports <- subset(data,name == "Sports")
celebrity <- subset(data,name == "Celebrity")
entertainment <- subset(data,name == "Entertainment")
travel <- subset(data,name == "Travel")
bizexp <- subset(data,name == "Business Experiences")
summary(sports)
data <- read.csv("~/Documents/Data/fy14 variance.csv")
View(data)
sports <- subset(data,name == "Sports")
celebrity <- subset(data,name == "Celebrity")
entertainment <- subset(data,name == "Entertainment")
travel <- subset(data,name == "Travel")
bizexp <- subset(data,name == "Business Experiences")
summary(data)
summary(sports)
summary(celebrity)
summary(entertainment)
summary(travel)
packages(Swirl)
packages("Swirl")
library("Swirl")
library(Swirl)
library("swirl", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
swirl()
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
menu()
help()
swirl()
menu()
Help()
Main()
Menu()
1
info()
main()
main()
head(flags)
head(flags)
dim(flags)
View(flags)
View(flags)
class(flags)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
length(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags,class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors,sum)
sapply(flag_colors, sum)
esc
help()
install.packages("ggplot2")
main()
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
data <- read.csv("~/Desktop/AS Acheive.csv")
View(data)
?subset
erin <- subset(data,Name == "Erin Hall")
jen <- subset(data,Name == "Jennifer Coughlin")
laura <- subset(data,Name == "Laura Deming")
dave <- subset(data,Name == "David Lee")
nic <- subset(data,Name == "Nicole Orzo")
ob <- subset(data,Name == "Olivia Barry")
lh <- subset(data,Name == "Logan Holzman")
stone <- subset(data,Name == "Caroline Stone")
meg <- subset(data,Name == "Meghan Sundermier")
sumamry(meg)
summary(meg
summary(meg)
data <- read.csv("~/Desktop/AS Acheive.csv")
View(data)
erin <- subset(data,Name == "Erin Hall")
jen <- subset(data,Name == "Jennifer Coughlin")
laura <- subset(data,Name == "Laura Deming")
dave <- subset(data,Name == "David Lee")
nic <- subset(data,Name == "Nicole Orzo")
ob <- subset(data,Name == "Olivia Barry")
lh <- subset(data,Name == "Logan Holzman")
meg <- subset(data,Name == "Meghan Sundermier")
summary(meg)
summary(nic)
summary(dave)
summary(jen)
summary(laura)
summary(lh)
summary(ob)
mlr09 <- read.csv("~/Downloads/mlr09.csv", header=FALSE)
View(mlr09)
sumary(mlr09)
summary(mlr09)
attach(mlr09)
lm(v4 ~ v1)
lm(V4 ~ V1)
lm(formula = V4 ~ V1)
rm(bizexp,celebrity,data,entertainment,sports,travel)
install.packages("twitteR")
library("twitteR")
public_tweets <- publicTimeline()
today_trends <- getTrends(period="daily",date=Sys.Date())
?twitteR
?today_trends
?today_trends()
load("~/Documents/Forecast Analysis/catalogitems.RData")
summary(d21)
View(`d21`)
View(d)
View(daily)
ggplot(daily,aes(x=lots,y=avg_ham))+geom_point()
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
ggplot(daily,aes(x=lots,y=avg_ham))+geom_point()
ggplot(daily,aes(x=lots,y=avg_ham))+geom_point()+geom_smooth()
ggplot(daily,aes(x=lots,y=avg_bids))+geom_point()+geom_smooth()
summary(daily$avg_bids)
head(arrange(daily,avg_bids))
summary(daily$avg_ham)
mean(d$ham)
View(d)
summary(d$hammer)
summary(d)
install.packages("tidyr")
library("tidyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
ggplot(daily,aes(x=lots,y=avg_bids))+geom_point()+geom_smooth()
ggplot(daily,aes(x=lots,y=avg_bids))+geom_point()+geom_smooth()+scale_y_log10()
ggplot(daily,aes(x=lots,y=avg_bids))+geom_point()+geom_smooth()+scale_y_log10()+scale_x_log10()
ggplot(daily,aes(x=lots,y=avg_bids))+geom_point()+geom_smooth()
ggplot(daily,aes(x=lots,y=avg_bids))+geom_point()+stat_smooth()+scale_y_log10()+scale_x_log10()
install.packages("Rdatasets")
load("~/Documents/Forecast Analysis/data/FEC.RData")
View(barry)
plot <- qplot(barry$date,barry$desc_run)
library(ggplot2)
library(dplyr)
library(scales)
plot <- qplot(barry$date,barry$desc_run)
plot(plot)
plot <- barry %>% filter(date>'2012-05-01') %>% qplot(barry$date,barry$desc_run)
plot(plot)
plot <- barry %>% filter(date>'2012-05-01') %>% qplot(date,desc_run)
barry %>% filter(date>'2012-05-01') %>% qplot(date,desc_run)
ggiris <- qplot(Petal.Width, Sepal.Length, data = iris, color = Species)
plot(ggiris)
py$ggplot(ggiris)
py <_ plotly
py <- plotly
library(plotly)
py <- plotly
py <- plotly()
py$ggplotly(ggiris)
spend <- barry %>% select(date,desc_run)
View(spend)
View(barry)
qplot(spend$date,spend$desc_run)
spend <- filter(spend,date>="2012-0-01")
spend <- filter(spend,date>='2012-01-01')
spend <- filter(spend,date>="2012-0-01")
qplot(spend$date,spend$desc_run)
qplot(spend$date,spend$desc_run,color=spend$description)
py <- plotly
py <- plotly()
spend <- qplot(spend$date,spend$desc_run,color=spend$description)
py$ggplotly(spend)
py$ggplotly(spend)
py$ggplotly(ggiris)
spend <- barry %>% select(date,desc_run)
spend <- filter(date<'2012-01-01')
spend <- filter(spend,date<'2012-01-01')
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line()
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_poinT()
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_point()
spend <- barry %>% select(date,desc_run)
spend <- filter(spend,date>='2012-01-01')
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+line(size=2)
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+line(size=(2))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+line(aes(size=2))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line(aes(size=2))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line(aes(size=1))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line(aes(size=rel(2)))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line(aes(size=.3
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line(aes(size=.3))
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line()
spend <- filter(spend,date<'2012-12-01',max(desc_run)>1000000)
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line()
spend <- filter(spend,date<'2012-12-01',max(desc_run)>5000000)
ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line()
py <- plotly()
spend_plot <- ggplot(spend,aes(x=date,y=desc_run,group=description,col=description))+geom_line()
py <- plotly()
py$ggplotly(spend_plot)
load("~/Dropbox/data/CitiBike/citi.RData")
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=2)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(lubridate)
citi %>% ggplot(aes(x=hour,fill=factor(wday))) + geom_density(alpha=.2)+facet_wrap(~wday,ncol=1)
citi %>% ggplot(aes(x=hour,fill=factor(wday))) + geom_density(alpha=.2)+facet_wrap(~wday,ncol=1)+theme_fivethirtyeight()+theme(legend.position="none")
citi %>% ggplot(aes(x=hour,fill=factor(wday))) + geom_density(alpha=.2)+facet_wrap(~wday,ncol=1)+theme_fivethirtyeight()+theme(legend.position="none",label.y.axis=element_blank())
citi %>% ggplot(aes(x=hour,fill=factor(wday))) + geom_density(alpha=.2)+facet_wrap(~wday,ncol=1)+theme_fivethirtyeight()+theme(legend.position="none",label.axis.y=element_blank())
citi %>% ggplot(aes(x=hour,fill=factor(wday))) + geom_density(alpha=.2)+facet_wrap(~wday,ncol=1)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=2)
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=1)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=1)+xlim(0,180)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=1)+xlim(0,30)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=1)+xlim(0,60)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + scale_x_log10() + facet_wrap(~wday,ncol=1)+xlim(0,45)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1)+xlim(0,45)+theme_fivethirtyeight()+theme(legend.position="none",axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1)+xlim(0,45)+theme_fivethirtyeight()+theme(,axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1)+xlim(0,45)+theme_fivethirtyeight()+theme(axis.text.y=element_blank())
citi %>% ggplot(aes(x=tripMin,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1)+xlim(0,45)+theme_fivethirtyeight()+theme(axis.text.y=element_blank(),legend.title=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + theme_fivethirtyeight() + theme(legend.title=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1) + theme_fivethirtyeight() + theme(legend.title=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1) + theme_fivethirtyeight() + theme(legend.title=element_blank(),axis.y.text=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1) + theme_fivethirtyeight() + theme(legend.title=element_blank(),axis.text.y=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + theme_fivethirtyeight() + theme(legend.title=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + theme_fivethirtyeight() + theme(legend.title=element_blank(),axis.text.y=element_blank())
citi %>% filter(usertype=="Subscriber") %>% group_by(hour)
citi %>% filter(usertype=="Subscriber") %>% group_by(hour) %>% summarize(count=n())
citi %>% filter(usertype=="Subscriber") %>% group_by(hour) %>% summarize(count=n()) %>% arrange(desc(count))
citi %>% ggplot(aes(x=time,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1) + theme_fivethirtyeight() + theme(legend.title=element_blank(),axis.text.y=element_blank())
citi %>% ggplot(aes(x=hour,group=usertype,fill=usertype)) + geom_density(alpha=.2) + facet_wrap(~wday,ncol=1) + theme_fivethirtyeight() + theme(legend.title=element_blank(),axis.text.y=element_blank())
library(rgdal)
library(spatstat)
library(maptools)
library(raster)
intsall.packages("spatstat")
install.packages("spatstat")
install.packages("raster")
library(rgdal)
library(spatstat)
library(maptools)
library(raster)
f <- readOGR("IN_NYC/sample_nyc.shp", "sample_nyc")
library(twittR)
library(twitteR)
?plyr
library(twitteR)
library(plyr)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "QfvGVcw5gx0NEoKObYzDud0eN"
consumerSecret <- "EhXZxJYXVlKncGggZ10K8C6tv5GtfmTMCJrg4e132vqjfge5Jp"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,consumerSecret=consumerSecret,requestURL=reqURL,accessURL=accessURL,authURL=authURL)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "http://api.twitter.com/oauth/access_token"
authURL <- "http://api.twitter.com/oauth/authorize"
consumerKey <- "c9Y93okSVDcNm8a06QrFXOvw6"
consumerSecret <- "MLsnNNCERSr7s8BC66rFT3V0sHft5jG2bgDePlepgGIHwklqMa"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,consumerSecret=consumerSecret,requestURL=reqURL,accessURL=accessURL,authURL=authURL)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
reqURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "c9Y93okSVDcNm8a06QrFXOvw6"
consumerSecret <- "MLsnNNCERSr7s8BC66rFT3V0sHft5jG2bgDePlepgGIHwklqMa"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,consumerSecret=consumerSecret,requestURL=reqURL,accessURL=accessURL,authURL=authURL)
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
twitCred$handshake(cainfo="cacert.pem")
registerTwitterOAuth(twitCred)
mh <- searchTwitter("Miami Heat",n=200)
head(mh)
mh <- searchTwitter("Miami Heat",n=200,lang="en")
head(mh)
mh <- searchTwitter("Miami Heat",n=1000,lang="en",since='2015-03-16',until='2015-03-17')
head(mh)
pos = scan('/Users/julian/Documents/positive-words.txt', what='character', comment.char=';')
mh.df <- do.call("rbind",lapply(mh,as.data.frame))
dim(mh.df)
View(mh.df)
mh.df2 <- twListToDF(mh)
rm(mh.df2)
library(tm)
install.packages("tm")
library(tm)
myCorpus <- Corpus(VectorSource(mh.df$text))
View(mh.df)
myCorpus <- tm_map(myCorpus,tolower)
myCorpus <- tm_map(myCorpus,content_transformer(tolower))
myCorpus <- tm_map(myCorpus,removePunctuation)
myCorpus <- tm_map(myCorpus,removeNumbers)
removeURL <- function(x) gsub("http[[:alnum:]]*","",x)
myCorpus <- tm_map(myCorpus,removeURL)
myCorpus <- tm_map(myCorpus,removeWords)
myCorpusCopy <- myCorpus
myCorpus <- tm_map(myCorpus,stemDocument)
for (i in 1:5){
cut(paste("[[",i,"]]",sep=""))
writeLines(myCorpus[[i]])
}
for (i in 1:5){
cat(paste("[[",i,"]]",sep=""))
writeLines(myCorpus[[i]])
}
mh <- searchTwitter("Miami Heat",n=1000,lang="en",since='2015-03-16',until='2015-03-17')
cb <- searchTwitter("@charitybuzz",n=1000,lang="en",since='2014-12-01')
cb.df <- twListToDF(cb)
View(cb.df)
mh <- searchTwitter("Miami Heat",n=1000,lang="en",since='2014-12-01')
mh.df <- twListToDF(mh)
class(mh)
class(mh[[1]])
tweet[[1]]$getText()
mh[[1]]$getText()
mh_text <- lapply(mh,function(x) x$getText())
rm(cb,cb.df,mh.df)
head(mh_text)
pos.words <- scan('/Users/pingelmo/Dropbox/data/twitter/sentiment.rar',comment.char=";")
pos.words <- scan('/Users/pingelmo/Dropbox/data/twitter/words/positive-words.txt',what='character',comment.char=";")
neg.words <- scan('/Users/pingelmo/Dropbox/data/twitter/words/negative-words.txt',what='character',comment.char=";")
sample = c("you're awesome and i love you", "I hate hate hate")
result <- score.sentiment(sample,pos.words,neg.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array ("a") of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result <- score.sentiment(sample,pos.words,neg.words)
result$score
mh.df <- twListToDF(mh)
mh.df$score <- score.sentiment (mh.df$text,pos.words,neg.words)
View(mh.df)
mh.df$score <- score.sentiment (mh.df$text,pos.words,neg.words,.progress='text')
View(mh.df)
mh_text$score <- score.sentiment (mh_text$text,pos.words,neg.words,.progress='text')
head(mh_text)
dim(mh_text)
mh_scores <- core.sentiment (mh_text,pos.words,neg.words,.progress='text')
mh_scores <- score.sentiment (mh_text,pos.words,neg.words,.progress='text')
corpus <- Corpus(VectorSource(mh_text))
tdm = TermDocumentMatrix(corpus,
control = list(removePunctuation = TRUE,
stopwords = c("machine", "learning", stopwords("english")),
removeNumbers = TRUE, tolower = TRUE))
tdm = TermDocumentMatrix(corpus, control = list(removePunctuation = TRUE,stopwords = stopwords("english"),removeNumbers = TRUE, tolower = TRUE))
tdm = TermDocumentMatrix(corpus, control = list(removePunctuation = TRUE,removeNumbers = TRUE, tolower = TRUE))
install.packages("tm.plugin.tags", repos = "http://datacube.wu.ac.at", type = "source")
library(tm.plugin.tags)
require(tm.plugin.tags)
tdm = TermDocumentMatrix(corpus, control = list(removePunctuation = TRUE,stopwords = stopwords("english"),removeNumbers = TRUE, tolower = TRUE))
library(tm)
require(tm.plugin.tags)
tdm = TermDocumentMatrix(corpus, control = list(removePunctuation = TRUE,stopwords = stopwords("english"),removeNumbers = TRUE, tolower = TRUE))
library(tm.plugin.tags)
tdm = TermDocumentMatrix(corpus)
tweets = searchTwitter("#abortion",n=1500)
tweets.text <- laply(tweets, function(x) x$getText())
head(tweets.text)
pos.words <- scan('/Users/pingelmo/Dropbox/data/twitter/words/positive-words.txt',what='character',comment.char=";")
neg.words <- scan('/Users/pingelmo/Dropbox/data/twitter/words/negative-words.txt',what='character',comment.char=";")
library(RCurl)
library(ROAuth)
library(twitteR)
library(stringr)
source("sentiment.R")
source(sentiment.R)
setwd("~/Dropbox/data/twitter")
source(sentiment.R)
source("sentiment.R")
source("sentiment.R")
source("sentiment.R")
analysis = score.sentiment(tweets.text,pos.words,neg.words)
tweets.text <- sapply(tweets.text,function(row) iconv(row, "latin1", "ASCII", sub=""))
analysis = score.sentiment(tweets.text,pos.words,neg.words)
analysis = score.sentiment(tweets.text,pos.words,neg.words)
head(analysis)
View(analysis)
table(analysis$score)
hist(analysis$score)
summary(analysis$score)
setwd("~/Dropbox/data/CitiBike")
load("~/Dropbox/data/CitiBike/citi.RData")
install.packages("dygraph")
install.packages("dygraphs")
library(dygraphs)
summary(citi$date)
View(citi)
summary(citi$tripDate)
citi %>% ggplot(aes(x=tripDate))+geom_line()
library(ggplot2)
library(splyr)
library(dplyr)
citi %>% ggplot(aes(x=tripDate))+geom_line()
citi %>% ggplot(aes(x=tripDate))+geom_density()
citi %>% ggplot(aes(x=tripDate))+geom_density(geom="line")
citi %>% ggplot(aes(x=tripDate))+geom_density(position="identity")
citi %>% ggplot(aes(x=tripDate))+geom_density(position="identity",geom="line")
citi %>% ggplot(aes(x=tripDate))+stat_density(position="identity",geom="line")
dygraph(tripDate)
cici%>%dygraph(tripDate)
citi %>% dygraph(tripDate)
sapply(citi,class)
as.POSIXct(citi[1,16])
as.POSIXlt(citi[1,16])
citi %>% dygraph(as.POSIXlt(tripDate))
lungdeaths <- cbind(mdeaths,fdeaths)
dygraph(lungdeaths)
sapply(lungdeaths,class)
dygraph(lungdeaths) %>% dyRangeSelector()
sapply(citi,class)
citi$dateXTS <- as.xts(citi$tripDate)
library(xts)
citi$dateXTS <- as.xts(citi$tripDate)
View(citi)
citi$dateXTS <- xts(citi$tripDate)
citi$dateXTS <- xts(citi[,-1],order.by=as.POXct(citi$tripDate))
citi$dateXTS <- xts(citi[,-1],order.by=as.POSIXct(citi$tripDate))
View(citi)
citi$dateXTS <- xts(citi[,-1],order.by=as.POSIXct(citi$tripDate,format="%Y-%m-%d"))
View(citi)
dygraph(citi$dateXTS)
